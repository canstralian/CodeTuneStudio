URL: https://github.com/foundation-model-stack/bamba.git
---
[Skip to content](https://github.com/foundation-model-stack/bamba#start-of-content)

You signed in with another tab or window. [Reload](https://github.com/foundation-model-stack/bamba) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/foundation-model-stack/bamba) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/foundation-model-stack/bamba) to refresh your session.Dismiss alert

[foundation-model-stack](https://github.com/foundation-model-stack)/ **[bamba](https://github.com/foundation-model-stack/bamba)** Public

- [Notifications](https://github.com/login?return_to=%2Ffoundation-model-stack%2Fbamba) You must be signed in to change notification settings
- [Fork\\
12](https://github.com/login?return_to=%2Ffoundation-model-stack%2Fbamba)
- [Star\\
82](https://github.com/login?return_to=%2Ffoundation-model-stack%2Fbamba)


Train, tune, and infer Bamba model


### License

[Apache-2.0 license](https://github.com/foundation-model-stack/bamba/blob/main/LICENSE)

[82\\
stars](https://github.com/foundation-model-stack/bamba/stargazers) [12\\
forks](https://github.com/foundation-model-stack/bamba/forks) [Branches](https://github.com/foundation-model-stack/bamba/branches) [Tags](https://github.com/foundation-model-stack/bamba/tags) [Activity](https://github.com/foundation-model-stack/bamba/activity)

[Star](https://github.com/login?return_to=%2Ffoundation-model-stack%2Fbamba)

[Notifications](https://github.com/login?return_to=%2Ffoundation-model-stack%2Fbamba) You must be signed in to change notification settings

# foundation-model-stack/bamba

main

[**7** Branches](https://github.com/foundation-model-stack/bamba/branches) [**0** Tags](https://github.com/foundation-model-stack/bamba/tags)

[Go to Branches page](https://github.com/foundation-model-stack/bamba/branches)[Go to Tags page](https://github.com/foundation-model-stack/bamba/tags)

Go to file

Code

## Folders and files

| Name | Name | Last commit message | Last commit date |
| --- | --- | --- | --- |
| ## Latest commit<br>## History<br>[166 Commits](https://github.com/foundation-model-stack/bamba/commits/main/) |
| [.github/ISSUE\_TEMPLATE](https://github.com/foundation-model-stack/bamba/tree/main/.github/ISSUE_TEMPLATE "This path skips through empty directories") | [.github/ISSUE\_TEMPLATE](https://github.com/foundation-model-stack/bamba/tree/main/.github/ISSUE_TEMPLATE "This path skips through empty directories") | [add feature request template](https://github.com/foundation-model-stack/bamba/commit/4afdfdf61d7958dfb167a488fea49f99badc37e7 "add feature request template  Signed-off-by: Sukriti-Sharma4 <sukriti.sharma4@ibm.com>") | Dec 11, 2024 |
| [blog](https://github.com/foundation-model-stack/bamba/tree/main/blog "blog") | [blog](https://github.com/foundation-model-stack/bamba/tree/main/blog "blog") | [Update bamba.md to sync with HF blog](https://github.com/foundation-model-stack/bamba/commit/75b46bf86554f4137f3cbdee9594bd22f2cb6858 "Update bamba.md to sync with HF blog") | Dec 18, 2024 |
| [evaluation](https://github.com/foundation-model-stack/bamba/tree/main/evaluation "evaluation") | [evaluation](https://github.com/foundation-model-stack/bamba/tree/main/evaluation "evaluation") | [add seed metadata](https://github.com/foundation-model-stack/bamba/commit/ef8d0a11718511ee66d28c8fc5a3bc41e20ef3aa "add seed metadata  Signed-off-by: Yotam Perlitz <y.perlitz@ibm.com>") | Jan 8, 2025 |
| [training](https://github.com/foundation-model-stack/bamba/tree/main/training "training") | [training](https://github.com/foundation-model-stack/bamba/tree/main/training "training") | [Contined Training README fix (](https://github.com/foundation-model-stack/bamba/commit/e0aae55592f20831c5e38f8e4e63020085f50adb "Contined Training README fix (#35)") [#35](https://github.com/foundation-model-stack/bamba/pull/35) [)](https://github.com/foundation-model-stack/bamba/commit/e0aae55592f20831c5e38f8e4e63020085f50adb "Contined Training README fix (#35)") | Jan 16, 2025 |
| [tuning](https://github.com/foundation-model-stack/bamba/tree/main/tuning "tuning") | [tuning](https://github.com/foundation-model-stack/bamba/tree/main/tuning "tuning") | [update model name (](https://github.com/foundation-model-stack/bamba/commit/3f7b3e699ab5f0641ec29e2b1629ce5652edc930 "update model name (#31)  Signed-off-by: Sukriti-Sharma4 <sukriti.sharma4@ibm.com>") [#31](https://github.com/foundation-model-stack/bamba/pull/31) [)](https://github.com/foundation-model-stack/bamba/commit/3f7b3e699ab5f0641ec29e2b1629ce5652edc930 "update model name (#31)  Signed-off-by: Sukriti-Sharma4 <sukriti.sharma4@ibm.com>") | Dec 19, 2024 |
| [.gitignore](https://github.com/foundation-model-stack/bamba/blob/main/.gitignore ".gitignore") | [.gitignore](https://github.com/foundation-model-stack/bamba/blob/main/.gitignore ".gitignore") | [remove scripts](https://github.com/foundation-model-stack/bamba/commit/7cb24fca36da86bd6750d5c5309623329e5de925 "remove scripts  Signed-off-by: Yotam Perlitz <y.perlitz@ibm.com>") | Dec 17, 2024 |
| [CONTRIBUTING.md](https://github.com/foundation-model-stack/bamba/blob/main/CONTRIBUTING.md "CONTRIBUTING.md") | [CONTRIBUTING.md](https://github.com/foundation-model-stack/bamba/blob/main/CONTRIBUTING.md "CONTRIBUTING.md") | [update contribution guidelines](https://github.com/foundation-model-stack/bamba/commit/d017e305a50c919f7b9657893ca02a2c1cbaadab "update contribution guidelines  Signed-off-by: Sukriti-Sharma4 <sukriti.sharma4@ibm.com>") | Dec 11, 2024 |
| [LICENSE](https://github.com/foundation-model-stack/bamba/blob/main/LICENSE "LICENSE") | [LICENSE](https://github.com/foundation-model-stack/bamba/blob/main/LICENSE "LICENSE") | [ADD LICENSE](https://github.com/foundation-model-stack/bamba/commit/7138a693a0e4148bcf4d0de0bece78d69df15065 "ADD LICENSE") | Dec 17, 2024 |
| [README.md](https://github.com/foundation-model-stack/bamba/blob/main/README.md "README.md") | [README.md](https://github.com/foundation-model-stack/bamba/blob/main/README.md "README.md") | [Fix training readme link](https://github.com/foundation-model-stack/bamba/commit/4158d55363cb6e0d173d976988436f76e49be3db "Fix training readme link") | Jan 10, 2025 |
| [bamba.jpeg](https://github.com/foundation-model-stack/bamba/blob/main/bamba.jpeg "bamba.jpeg") | [bamba.jpeg](https://github.com/foundation-model-stack/bamba/blob/main/bamba.jpeg "bamba.jpeg") | [init](https://github.com/foundation-model-stack/bamba/commit/efd3419bc2712291ca084b86eaa5b4aac76269b5 "init") | Nov 27, 2024 |
| [code-of-conduct.md](https://github.com/foundation-model-stack/bamba/blob/main/code-of-conduct.md "code-of-conduct.md") | [code-of-conduct.md](https://github.com/foundation-model-stack/bamba/blob/main/code-of-conduct.md "code-of-conduct.md") | [add contributing guidelines](https://github.com/foundation-model-stack/bamba/commit/629a1fae881ac98b41a59fff65a41e9e98e0d0cd "add contributing guidelines  Signed-off-by: Sukriti-Sharma4 <sukriti.sharma4@ibm.com>") | Dec 11, 2024 |
| [text\_generation.py](https://github.com/foundation-model-stack/bamba/blob/main/text_generation.py "text_generation.py") | [text\_generation.py](https://github.com/foundation-model-stack/bamba/blob/main/text_generation.py "text_generation.py") | [Readme fixes (front page and training) (](https://github.com/foundation-model-stack/bamba/commit/91030073d66c51ca56d5342cb0b05b3fe99d73f8 "Readme fixes (front page and training) (#29)  * Add files via upload  * Update README.md  Added py script for text generation  * Update README.md  Torchrun command for pretraining  * Update README.md  * Update README.md  * Update README.md  * Update README.md  * Update README.md  * Added links to Bamba checkpoints  * Update README.md  * changed mamba-new to main  * Update README.md  * Create training.md  * Update README.md  * Update README.md  * Update training.md  * Update text_generation.py  * Update training.md (dataloader link)  * Update README.md (model config)") [#29](https://github.com/foundation-model-stack/bamba/pull/29) [)](https://github.com/foundation-model-stack/bamba/commit/91030073d66c51ca56d5342cb0b05b3fe99d73f8 "Readme fixes (front page and training) (#29)  * Add files via upload  * Update README.md  Added py script for text generation  * Update README.md  Torchrun command for pretraining  * Update README.md  * Update README.md  * Update README.md  * Update README.md  * Update README.md  * Added links to Bamba checkpoints  * Update README.md  * changed mamba-new to main  * Update README.md  * Create training.md  * Update README.md  * Update README.md  * Update training.md  * Update text_generation.py  * Update training.md (dataloader link)  * Update README.md (model config)") | Dec 18, 2024 |
| View all files |

## Repository files navigation

# Bamba

[Permalink: Bamba](https://github.com/foundation-model-stack/bamba#bamba)

[![](https://github.com/foundation-model-stack/bamba/raw/main/bamba.jpeg)](https://github.com/foundation-model-stack/bamba/blob/main/bamba.jpeg)

ðŸ¤— [Bamba on Hugging Face](https://huggingface.co/collections/ibm-fms/bamba-674f1388b9bbc98b413c7bab)Â  \| [Bamba Blog](https://huggingface.co/blog/bamba)

Bamba-9B is a decoder-only language model based on the [Mamba-2](https://github.com/state-spaces/mamba) architecture and is designed to handle a wide range of text generation tasks. It is trained from scratch using a two-stage training approach. In the first stage, the model is trained on 2 trillion tokens from the Dolma v1.7 dataset. In the second stage, it undergoes additional training on 200 billion tokens, leveraging a carefully curated blend of high-quality data to further refine its performance and enhance output quality.

## Installation

[Permalink: Installation](https://github.com/foundation-model-stack/bamba#installation)

Besides [PyTorch](https://pytorch.org/), you would need a few [extra dependencies](https://github.com/state-spaces/mamba?tab=readme-ov-file#installation) for
Mamba models.

We found some of these dependencies picky on PyTorch versions when doing pip install, so
the best way is to build from source for all Mamba dependencies if you hit dependency
issue with your env:

```
git clone https://github.com/Dao-AILab/causal-conv1d.git
cd causal-conv1d && pip install . && cd ..
git clone https://github.com/state-spaces/mamba.git
cd mamba && pip install . && cd ..
git clone https://github.com/Dao-AILab/flash-attention.git
cd flash-attention && pip install . && cd ..
```

For users using our HF versions of the model, you would need to install the latest transformers which includes our newly merged implementation for our Bamba models:

```
pip install git+https://github.com/huggingface/transformers.git
```

## Models

[Permalink: Models](https://github.com/foundation-model-stack/bamba#models)

| Model | Params | \# Layers | Hidden Dim. | Attention Heads | GQA | KV Heads | Context Length | Tied Embeddings |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Bamba | 9B (9.78B) | 32 | 4096 | 32 | Yes | 8 | 4096 | False |

### Checkpoints

[Permalink: Checkpoints](https://github.com/foundation-model-stack/bamba#checkpoints)

You can find links to our model checkpoints here: [Bamba Models](https://huggingface.co/collections/ibm-fms/bamba-674f1388b9bbc98b413c7bab)

## Inference

[Permalink: Inference](https://github.com/foundation-model-stack/bamba#inference)

You can use the following command to perform text generation using one of our checkpoints provided above:

```
python text_generation.py --model_path ibm-fms/Bamba-9B --tokenizer_path ibm-fms/Bamba-9B --prompt "The largest living mammal on Earth is " --max_new_tokens 128
```

## Training

[Permalink: Training](https://github.com/foundation-model-stack/bamba#training)

Details on training can be found [here](https://github.com/foundation-model-stack/bamba/blob/main/training/README.md).

## Benchmark scores

[Permalink: Benchmark scores](https://github.com/foundation-model-stack/bamba#benchmark-scores)

### Base pretrained models

[Permalink: Base pretrained models](https://github.com/foundation-model-stack/bamba#base-pretrained-models)

|     |     |     |
| --- | --- | --- |
| **Category** | **Benchmark** | **Bamba 9B (2.2T)** |
| General | MMLU (5-shot) | 60.77 |
| ARC-C (25-shot) | 63.23 |
| GSM8K (5-shot) | 36.77 |
| Hellaswag (10-shot) | 81.8 |
| OpenbookQA (5-shot) | 47.6 |
| Piqa (5-shot) | 82.26 |
| TruthfulQA (0-shot) | 49.21 |
| Winogrande (5-shot) | 76.87 |
| HF OpenLLM- V2\* | MMLU-PRO (5-shot) | 17.53 |
| BBH (3-shot) | 17.4 |
| GPQA (0-shot) | 4.14 |
| IFEval (0-shot) | 15.16 |
| MATH Lvl 5 (4-shot) | 1.66 |
| MuSR (0-shot) | 9.59 |
| Safety Tasks | PopQA (5-shot) | 20.5 |
| Toxigen (5-shot) | 57.4 |
| BBQ (5-shot) | 44.2 |
| Crows-pairs english (5-shot) | 70.78 |

\*For the v2 leaderboard results, we perform [normalization](https://huggingface.co/docs/leaderboards/open_llm_leaderboard/normalization) and report the normalized results.

Further details on our evaluation and normalization detailes along with run and analysis scripts can be found [here](https://github.com/foundation-model-stack/bamba/blob/main/evaluation/README.md).

## Fine-tuning

[Permalink: Fine-tuning](https://github.com/foundation-model-stack/bamba#fine-tuning)

This [example](https://github.com/foundation-model-stack/bamba/blob/main/tuning/Fine-tuning.md) shows how to fine tune the bamba model for a specific task using [SFT Trainer](https://huggingface.co/docs/trl/en/sft_trainer#supervised-fine-tuning-trainer).

## Quantization

[Permalink: Quantization](https://github.com/foundation-model-stack/bamba#quantization)

We can create a (FP8) quantized model using [`fms-model-optimizer`](https://github.com/foundation-model-stack/fms-model-optimizer/), which will make the storage and inference even more efficient.

```
python -m fms_mo.run_quant \
    --model_name_or_path <"path_to_original_model"> \
    --quant_method fp8 \
    --torch_dtype bfloat16 \
    --output_dir <"path_to_save_new_model">
```

Model size comparison before and after FP8:

|  | original | quantized |
| :-: | --: | --: |
| memory (total) | 39.12 GB | 10.83 GB |
| memory (break-down) | `torch.float32` 39.12 GB | `torch.bfloat16` 2.10 GB<br>`torch.float8_e4m3fn` 8.73 GB |

More details about `fms-model-optimizer` can be found [here](https://github.com/foundation-model-stack/fms-model-optimizer/tree/main/examples/FP8_QUANT#quickstart).

## Llama.cpp

[Permalink: Llama.cpp](https://github.com/foundation-model-stack/bamba#llamacpp)

There is preliminary work to enable running Bamba architecture models using [llama.cpp](https://github.com/ggerganov/llama.cpp). This is work-in-progress, so should only be used as a guide for the adventurous!

### Known Limitations

[Permalink: Known Limitations](https://github.com/foundation-model-stack/bamba#known-limitations)

- Currently, inference is only supported on CPUs
- Models quantized with `llama-quantize` exhibit bad performance

### Setup

[Permalink: Setup](https://github.com/foundation-model-stack/bamba#setup)

To enable Bamba support, you'll need to build from source using [Gabe's fork](https://github.com/gabe-l-hart/llama.cpp/tree/BambaArchitecture).

```
git clone --branch BambaArchitecture git@github.com:gabe-l-hart/llama.cpp.git
cd llama.cpp
mkdir build
cd build
# NOTE: To build with debug symbols and extra logging, use CMAKE_BUILD_TYPE=Debug
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j
```

### Conversion to GGUF

[Permalink: Conversion to GGUF](https://github.com/foundation-model-stack/bamba#conversion-to-gguf)

You can use a pre-converted GGUF file from Huggingface (e.g. [bamba-9b.gguf](https://huggingface.co/ibm-fms/Bamba-9B/blob/main/bamba-9b.gguf)). If one doesn't exist, you can use the [convert\_hf\_to\_gguf.py](https://github.com/gabe-l-hart/llama.cpp/blob/BambaArchitecture/convert_hf_to_gguf.py) script from Gabe's fork to perform the conversion manually.

```
# Install the python dependencies
cd /path/to/llama.cpp
pip install -r requirements/requirements-convert_hf_to_gguf.txt

# Perform the conversion
./convert_hf_to_gguf.py /path/to/bamba-model --outfile /path/to/bamba-model/bamba-model.gguf
```

### Run with llama-cli

[Permalink: Run with llama-cli](https://github.com/foundation-model-stack/bamba#run-with-llama-cli)

```
# Run the model with no layers on the GPU (CPU-only)
cd /path/to/llama.cpp
./bin/llama-cli  -ngl 0 -m /path/to/bamba-model/bamba-model.gguf -p "Tell me a story about a developer and their dog"
```

### Quantization with llama-quantize

[Permalink: Quantization with llama-quantize](https://github.com/foundation-model-stack/bamba#quantization-with-llama-quantize)

You can (optionally) quantize the GGUF model using `llama.cpp`'s built in quantizaiton tool `llama-quantize`.

```
# Run the quantization (see llama-quantize --help for all quant types)
cd /path/to/llama.cpp
./build/bin/llama-quantize /path/to/bamba-model/bamba-model.gguf Q4_K_M
```

## Contributors

[Permalink: Contributors](https://github.com/foundation-model-stack/bamba#contributors)

- **Data collection and curation**: We acknowledge and thank AllenAI team for making a high quality open source dataset Dolma as well as Hugging Face data team for making FineWeb-edu and Cosmopedia available. These are tremendous contributions which enabled us to create the model.
- **Data preprocessing**: We thank IBM's internal data preprocessing team, specifically Tuan Hoang Trong, Syed Zawad, Jay Gala, and Ryan Gordon for helping tokenize the data at scale. The code for tokenization is available [here](https://github.com/IBM/data-prep-kit).
- **Model architecture**: The model architecture design was jointly done by Princeton, CMU, IBM, and UIUC and involved the following folks: Tri Dao (Princeton), Albert Gu (CMU), Linsong Chu (IBM), Davis Wertheimer (IBM), Minjia Zhang (UIUC), Mudhakar Srivatsa (IBM), and Raghu Ganti (IBM).
- **Model training**: Model training was performed primarily by the IBM team using the Mamba2 kernels and layer implementation from Tri Dao and Albert Gu. The following folks from IBM were primarily involved: Linsong Chu, Divya Kumari, Davis Wertheimer, Raghu Ganti, and Dakshi Agrawal.
- **Model tuning**: Tuning of the model was enabled and verified in [TRL](https://github.com/huggingface/trl) by the IBM team, involving Sukriti Sharma and Anh Uong.
- **Model inference**: Model inference in `transformers`, `vLLM`, and `llama.cpp` builds on the kernels written by Princeton and CMU. The IBM team is working with the community to enable it in various ecosystems. The team includes Fabian Lim, Antoni viros i Martin, Adnan Hoque, Jamie Yang, Nelson Nimura Gonzalez, Joshua Rosenkranz, Nick Hill, and Gabe Goodhart.
- **Quantization**: Quantization is led by the IBM team - Naigang Wang and Charlie Liu.
- **Evaluations**: Evaluations are led by a team in IBM with long context evaluations being performed by UIUC, involving the following folks: Yotam Perlitz, Ofir Arviv, Michal Shmueli-Scheuer (IBM), Haoechen Shen, and Minjia Zhang (UIUC).

Finally, we would like to thank our leadership for their support in this effort - Priya Nagpurkar, David Cox, Sriram Raghavan, Aya Soffer, Ruchir Puri, and Mukesh Khare.

We would also like to thank the community, in particular Pablo Montalvo-Leroux, Aritra Roy Gosthipaty, and Vaibhav Srivastav from Hugging Face and Stas Bekman from Contextual AI who provided valuable feedback to this blog and the PRs into transformers. Further, we would like to thank Tyler Michael Smith from Neural Magic, who is shepherding the integration with vLLM.

A huge shoutout to Meta PyTorch, AllenAI, and Hugging Face teams for their contributions to the open initative, PyTorch FSDP allowed us to smoothly train this model and the data from Dolma and Fineweb/Cosmopedia made this model today!

## About

Train, tune, and infer Bamba model


### Resources

[Readme](https://github.com/foundation-model-stack/bamba#readme-ov-file)

### License

[Apache-2.0 license](https://github.com/foundation-model-stack/bamba#Apache-2.0-1-ov-file)

### Code of conduct

[Code of conduct](https://github.com/foundation-model-stack/bamba#coc-ov-file)

[Activity](https://github.com/foundation-model-stack/bamba/activity)

[Custom properties](https://github.com/foundation-model-stack/bamba/custom-properties)

### Stars

[**82**\\
stars](https://github.com/foundation-model-stack/bamba/stargazers)

### Watchers

[**12**\\
watching](https://github.com/foundation-model-stack/bamba/watchers)

### Forks

[**12**\\
forks](https://github.com/foundation-model-stack/bamba/forks)

[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Ffoundation-model-stack%2Fbamba&report=foundation-model-stack+%28user%29)

## [Releases](https://github.com/foundation-model-stack/bamba/releases)

No releases published

## [Packages\  0](https://github.com/orgs/foundation-model-stack/packages?repo_name=bamba)

No packages published

## [Contributors\  13](https://github.com/foundation-model-stack/bamba/graphs/contributors)

- [![@raghukiran1224](https://avatars.githubusercontent.com/u/8322403?s=64&v=4)](https://github.com/raghukiran1224)
- [![@perlitz](https://avatars.githubusercontent.com/u/4630195?s=64&v=4)](https://github.com/perlitz)
- [![@lchu6](https://avatars.githubusercontent.com/u/20955448?s=64&v=4)](https://github.com/lchu6)
- [![@divya-kumari32](https://avatars.githubusercontent.com/u/72085811?s=64&v=4)](https://github.com/divya-kumari32)
- [![@Ssukriti](https://avatars.githubusercontent.com/u/16025630?s=64&v=4)](https://github.com/Ssukriti)
- [![@gitMichal](https://avatars.githubusercontent.com/u/13574201?s=64&v=4)](https://github.com/gitMichal)
- [![@daviswer](https://avatars.githubusercontent.com/u/9604893?s=64&v=4)](https://github.com/daviswer)
- [![@OfirArviv](https://avatars.githubusercontent.com/u/22588859?s=64&v=4)](https://github.com/OfirArviv)
- [![@mudhakar](https://avatars.githubusercontent.com/u/4701183?s=64&v=4)](https://github.com/mudhakar)
- [![@dakshiagrawal](https://avatars.githubusercontent.com/u/12987856?s=64&v=4)](https://github.com/dakshiagrawal)
- [![@garrett361](https://avatars.githubusercontent.com/u/44747910?s=64&v=4)](https://github.com/garrett361)
- [![@Supercomputing-System-AI-Lab](https://avatars.githubusercontent.com/u/187124523?s=64&v=4)](https://github.com/Supercomputing-System-AI-Lab)
- [![@gabe-l-hart](https://avatars.githubusercontent.com/u/1254484?s=64&v=4)](https://github.com/gabe-l-hart)

## Languages

- [Python94.9%](https://github.com/foundation-model-stack/bamba/search?l=python)
- [Shell5.1%](https://github.com/foundation-model-stack/bamba/search?l=shell)

You canâ€™t perform that action at this time.