# ğŸµğŸ’» CodeTuneStudio

[![PyPI version](https://badge.fury.io/py/codetunestudio.svg)](https://pypi.org/project/codetunestudio/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-%3E%3D3.11-blue.svg)](https://www.python.org/downloads)
[![Code style: ruff](https://img.shields.io/badge/code%20style-ruff-000000.svg)](https://github.com/astral-sh/ruff)
[![CI Pipeline](https://github.com/canstralian/CodeTuneStudio/actions/workflows/ci.yml/badge.svg)](https://github.com/canstralian/CodeTuneStudio/actions/workflows/ci.yml)

---

ğŸ¯ **Optimize. Fine-tune. Perfect Your ML Models.**

CodeTuneStudio is an AI-powered platform for fine-tuning machine learning models with parameter-efficient training (PEFT/LoRA), real-time monitoring, and extensible plugin architecture â€” all within an intuitive Streamlit interface.

---

## âœ¨ Features

- ğŸ¤– **ML Model Fine-tuning** â€” Support for CodeT5, Replit-v1.5, and custom models
- âš¡ **PEFT/LoRA Training** â€” Parameter-efficient fine-tuning with quantization support
- ğŸ“Š **Real-time Monitoring** â€” Live training metrics and visualization with Plotly
- ğŸ”Œ **Plugin Architecture** â€” Extensible tool system with OpenAI, Anthropic integrations
- ğŸ’¾ **Experiment Tracking** â€” PostgreSQL/SQLite backend for configuration and metrics
- ğŸš€ **Distributed Training** â€” Multi-GPU support with automatic optimization
- ğŸ¨ **Dataset Management** â€” Built-in support for HuggingFace datasets and Argilla
- ğŸ“ˆ **Version Control** â€” Model versioning and experiment comparison

---

## ğŸ› ï¸ Prerequisites

- ğŸ **Python** 3.11 or higher
- ğŸ’» **uv** package manager (recommended) or pip
- ğŸ® **CUDA** (optional, for GPU acceleration)

---

## ğŸ“¥ Installation

### Quick Start (Recommended)

```bash
# Install uv (fast package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone the repository
git clone https://github.com/canstralian/CodeTuneStudio.git
cd CodeTuneStudio

# Install dependencies
uv pip install -e ".[dev]"

# Setup environment
cp .env.example .env
# Edit .env with your API keys and configuration
```

### Traditional Installation

```bash
# Clone the repository
git clone https://github.com/canstralian/CodeTuneStudio.git
cd CodeTuneStudio

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"

# Setup environment
cp .env.example .env
# Edit .env with your API keys and configuration
```

### PyPI Installation (Coming Soon)

```bash
pip install codetunestudio
```

---

## âš™ï¸ Configuration

Create a `.env` file with your configuration:

```bash
# Database (use PostgreSQL for production)
DATABASE_URL=sqlite:///database.db

# AI/ML API Keys (optional, for plugins)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
HF_TOKEN=hf_...

# Argilla (optional, for dataset management)
ARGILLA_API_KEY=...
ARGILLA_WORKSPACE=default

# Distributed Training (optional)
MASTER_ADDR=localhost
MASTER_PORT=12355
```

See `.env.example` for complete configuration options.

---

## ğŸš€ Usage

### Starting the Application

```bash
# Run Streamlit interface
python app.py

# Or use streamlit directly
streamlit run app.py
```

Access the interface at **http://localhost:7860**

### Using Flask CLI

```bash
# Database migrations
python manage.py db init
python manage.py db migrate -m "Initial migration"
python manage.py db upgrade

# Interactive shell
python manage.py shell
```

### Running with Make

```bash
# Install dependencies
make install

# Run application
make run

# Run tests
make test

# Lint code
make lint

# Format code
make format

# Clean build artifacts
make clean
```

---

## ğŸ“ Project Structure

```
CodeTuneStudio/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ manage.py                   # Flask CLI for database management
â”œâ”€â”€ pyproject.toml              # Project metadata and dependencies
â”œâ”€â”€ .env.example                # Environment variable template
â”‚
â”œâ”€â”€ components/                 # Streamlit UI components
â”‚   â”œâ”€â”€ dataset_selector.py    # Dataset browsing and selection
â”‚   â”œâ”€â”€ parameter_config.py    # Training hyperparameter configuration
â”‚   â”œâ”€â”€ training_monitor.py    # Real-time training visualization
â”‚   â”œâ”€â”€ experiment_compare.py  # Multi-experiment comparison
â”‚   â”œâ”€â”€ plugin_manager.py      # Plugin lifecycle management
â”‚   â”œâ”€â”€ tokenizer_builder.py   # Custom tokenizer creation
â”‚   â””â”€â”€ documentation_viewer.py # In-app documentation
â”‚
â”œâ”€â”€ utils/                      # Core utilities
â”‚   â”œâ”€â”€ config.py              # Centralized configuration
â”‚   â”œâ”€â”€ logging_config.py      # Logging setup
â”‚   â”œâ”€â”€ database.py            # Database models and session management
â”‚   â”œâ”€â”€ config_validator.py    # Configuration validation
â”‚   â”œâ”€â”€ peft_trainer.py        # PEFT/LoRA training logic
â”‚   â”œâ”€â”€ distributed_trainer.py # Multi-GPU training orchestration
â”‚   â”œâ”€â”€ model_inference.py     # Model loading and inference
â”‚   â”œâ”€â”€ model_versioning.py    # Experiment version control
â”‚   â”œâ”€â”€ visualization.py       # Plotly chart generation
â”‚   â””â”€â”€ plugins/               # Plugin system
â”‚       â”œâ”€â”€ base.py            # AgentTool abstract base class
â”‚       â””â”€â”€ registry.py        # Plugin discovery and registration
â”‚
â”œâ”€â”€ plugins/                    # Extensible tool plugins
â”‚   â”œâ”€â”€ code_analyzer.py       # Python AST-based code analysis
â”‚   â”œâ”€â”€ openai_code_analyzer.py # OpenAI GPT-powered analysis
â”‚   â””â”€â”€ anthropic_code_suggester.py # Claude-powered suggestions
â”‚
â”œâ”€â”€ tests/                      # Test suite
â”‚   â”œâ”€â”€ test_app.py
â”‚   â”œâ”€â”€ test_db_check.py
â”‚   â””â”€â”€ test_manage.py
â”‚
â””â”€â”€ .github/workflows/          # CI/CD pipelines
    â”œâ”€â”€ ci.yml                 # Linting and testing
    â”œâ”€â”€ huggingface-deploy.yml # HF Hub deployment
    â””â”€â”€ python-style-checks.yml # Code style validation
```

---

## ğŸ¯ Key Workflows

### Fine-tuning a Model

1. **Select Dataset**: Browse HuggingFace datasets or connect to Argilla
2. **Configure Training**: Set hyperparameters (batch size, learning rate, epochs)
3. **Monitor Progress**: View real-time loss curves and metrics
4. **Compare Experiments**: Analyze multiple training runs side-by-side
5. **Export Model**: Save fine-tuned model with version control

### Creating Custom Plugins

```python
from utils.plugins.base import AgentTool, ToolMetadata

class MyCustomTool(AgentTool):
    def __init__(self):
        super().__init__()
        self.metadata = ToolMetadata(
            name="my_custom_tool",
            description="Does something amazing",
            version="0.1.0",
            author="Your Name",
            tags=["custom", "analysis"]
        )

    def validate_inputs(self, inputs: dict) -> bool:
        return "data" in inputs

    def execute(self, inputs: dict) -> dict:
        # Your logic here
        return {"result": "success"}
```

Place in `plugins/` directory and it will be auto-discovered on startup.

---

## ğŸ§ª Development

### Running Tests

```bash
# Run all tests
python -m unittest discover -s tests

# Run specific test file
python -m unittest tests.test_app

# With coverage
pytest --cov=. --cov-report=html
```

### Code Quality

```bash
# Lint with Ruff
ruff check .

# Format code
ruff format .

# Type checking (optional)
mypy .
```

### Pre-commit Hooks

```bash
# Install pre-commit
pip install pre-commit

# Setup hooks
pre-commit install

# Run manually
pre-commit run --all-files
```

---

## ğŸ“Š Supported Models & Datasets

### Models
- CodeT5 (Salesforce)
- Replit-v1.5
- Custom transformer models via HuggingFace

### Datasets
- HuggingFace Hub datasets
- Argilla datasets
- Reddit code datasets
- Custom JSON/CSV datasets

### Training Techniques
- LoRA (Low-Rank Adaptation)
- QLoRA (Quantized LoRA)
- Full fine-tuning
- 4-bit/8-bit quantization

---

## ğŸ› Troubleshooting

### Common Issues

**Database connection errors:**
```bash
# Reset database
rm database.db
python manage.py db upgrade
```

**Plugin not loading:**
- Check API keys in `.env`
- Verify plugin file is in `plugins/` directory
- Check logs for errors: `tail -f codetunestudio.log`

**CUDA out of memory:**
- Reduce batch size
- Enable gradient checkpointing
- Use quantization (4-bit/8-bit)

See [CLAUDE.md](CLAUDE.md) for detailed architecture documentation.

---

## ğŸ¤ Contributing

We welcome contributions! ğŸ«¶

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## ğŸ“œ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgements

- **HuggingFace** for transformers and datasets
- **Streamlit** for the beautiful UI framework
- **PEFT** library for parameter-efficient training
- The open-source ML community

---

## ğŸ“§ Support

- ğŸ› **Issues**: [GitHub Issues](https://github.com/canstralian/CodeTuneStudio/issues)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/canstralian/CodeTuneStudio/discussions)
- ğŸ“– **Documentation**: [CLAUDE.md](CLAUDE.md)

---

> _"Code is like music â€” when fine-tuned, it performs perfectly."_ ğŸµğŸ’»

**Built with â¤ï¸ by the CodeTuneStudio Team**
